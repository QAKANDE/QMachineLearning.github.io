{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import time\n",
    "from os import makedirs\n",
    "from keras.preprocessing.image import save_img\n",
    "import sys \n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D \n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense \n",
    "from keras.layers import Flatten \n",
    "from keras.layers import  Dropout\n",
    "from keras.optimizers import SGD \n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib.pyplot import plot\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "starttime = time.time()\n",
    "classlist = ['airplane','automobile','bird','cat','deer']\n",
    "label_names = np.array(('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GetTrainingData i.e data the network would be trained with.\n",
    "def getTrainingData(train_data_normalized,train_labels,label_names,batchcount):\n",
    "    traindatacount = batchcount   \n",
    "    classlist = ['airplane','automobile','bird','cat','deer']\n",
    "    classcounterdict = {'airplane':0,'automobile':0,'bird':0,'cat':0,'deer':0}\n",
    "    newtraindata, newtrainlabels,newfilenames = [], [],[]\n",
    "    counter = 1\n",
    "    while counter < 50000:\n",
    "        label = label_names[train_labels[counter]][0]        \n",
    "        img_array = train_data_normalized[counter,:,:,:]\n",
    "        if label in classlist:          \n",
    "            if classcounterdict[label] + 1 <= traindatacount:\n",
    "                newtraindata.append(img_array)\n",
    "                newtrainlabels.append(train_labels[counter])               \n",
    "                classcounterdict[label] = classcounterdict[label] + 1\n",
    "        counter = counter + 1\n",
    "    newtraindata = np.array(newtraindata)   \n",
    "    newtrainlabels = np.array(newtrainlabels)\n",
    "    return newtraindata,newtrainlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test data ,this data is used for evaluation after training is performed \n",
    "def getTestData(label_names,test_data_train_data_normalized,test_labels,batchcount):\n",
    "    testdatacount = batchcount  \n",
    "    classlist = ['airplane','automobile','bird','cat','deer']\n",
    "    classcounterdict = {\"airplane\":0,\"automobile\":0,\"bird\":0,\"cat\":0,\"deer\":0}\n",
    "    newtestdata, newtestlabels,newtestfilenames = [], [],[]\n",
    "    counter = 1\n",
    "    while counter < 10000:\n",
    "        label = label_names[test_labels[counter]][0]\n",
    "        img_array = test_data_train_data_normalized[counter,:,:,:]\n",
    "        if label in classlist:\n",
    "            if classcounterdict[label] + 1 <= testdatacount:            \n",
    "                newtestdata.append(img_array)            \n",
    "                newtestlabels.append(test_labels[counter])             \n",
    "                classcounterdict[label] = classcounterdict[label] + 1\n",
    "        counter = counter + 1\n",
    "    newtestdata = np.array(newtestdata)   \n",
    "    newtestlabels = np.array(newtestlabels)\n",
    "    return newtestdata,newtestlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize both train and test data \n",
    "def  prep_pixels(train,test):\n",
    "     train_norm = train.astype('float32')\n",
    "     test_norm = test.astype('float32')\n",
    "     train_norm = train_norm / 255 \n",
    "     test_norm = test_norm / 255\n",
    "     return  train_norm , test_norm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This a VGG model architecture\n",
    "def define_model(dropoutval,learningRate,momentumvalue,epochs):    \n",
    "     model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(dropoutval)) \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(dropoutval)) \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(dropoutval))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(dropoutval))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')) \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(dropoutval))\n",
    "    model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    decay_rate = learningRate / epochs \n",
    "    sgd = SGD(lr=learningRate, momentum=momentumvalue, decay=decay_rate, nesterov=False) \n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate network after training is done \n",
    "def evaluate_model_new(dataX, dataY,testdataX,testdataY,batchsize,epochsize,model):\n",
    "    scores, histories = list(), list()\n",
    "    filepath=\"weights.best.hdf5\" \n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max') \n",
    "    callbacks_list = [checkpoint]\n",
    "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1,horizontal_flip=True, vertical_flip=True) \n",
    "    it_train = datagen.flow(dataX, dataY, batch_size=batchsize) \n",
    "    steps = int(dataX.shape[0] / batchsize)   \n",
    "    history = model.fit_generator(it_train, steps_per_epoch=steps, epochs=epochsize, validation_data=(testdataX, testdataY), verbose=0,callbacks=callbacks_list) \n",
    "    _, acc = model.evaluate(testdataX, testdataY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))    \n",
    "    histories.append(history)\n",
    "    scores.append(acc)\n",
    "    return scores, histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Accuracy and Loss curve \n",
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        pyplot.subplot(211)\n",
    "        pyplot.title('Cross Entropy Loss')\n",
    "        pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "        pyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "        # plot accuracy\n",
    "        pyplot.subplot(212)\n",
    "        pyplot.title('Classification Accuracy')\n",
    "        pyplot.plot(histories[i].history['acc'], color='blue', label='train')\n",
    "        pyplot.plot(histories[i].history['val_acc'], color='orange', label='test')\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate accuracy\n",
    "def summarize_performance(scores):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "    # box and whisker plots of results\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and evaluation is performed here , we call all functions here .\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "train_data_normalized,test_data_train_data_normalized = prep_pixels(x_train,x_test)\n",
    "trainingDataRecordsPerClassCount = 5000\n",
    "testDataRecordsPerClassCount = 1000\n",
    "batchsize = 32\n",
    "epochsize = 120\n",
    "dropoutval = 0.2\n",
    "learningRate = 0.01\n",
    "momentumvalue = 0.9\n",
    "newtraindata,newtrainlabels = getTrainingData(train_data_normalized,y_train,label_names,trainingDataRecordsPerClassCount)\n",
    "newtestdata,newtestlabels = getTestData(label_names,test_data_train_data_normalized,y_test,testDataRecordsPerClassCount) \n",
    "newtrainlabels = to_categorical(newtrainlabels)\n",
    "newtestlabels =  to_categorical(newtestlabels)\n",
    "model=define_model(dropoutval,learningRate,momentumvalue,epochsize)\n",
    "scores, histories = evaluate_model_new(newtraindata, newtrainlabels,newtestdata,newtestlabels,batchsize,epochsize,model)\n",
    "# learning curves\n",
    "summarize_diagnostics(histories)\n",
    "summary_performances(scores)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
